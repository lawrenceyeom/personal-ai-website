// utils/llm/test-integration.ts
// LLMæ¨¡å—é›†æˆæµ‹è¯•

import { 
  callLLMStream, 
  getModelMapping, 
  isReasoningModel, 
  modelSupportsTools,
  getProviderInfo,
  getRecommendedModels,
  getModelsByProvider,
  LLMRequest 
} from './index';

/**
 * æµ‹è¯•åŸºæœ¬åŠŸèƒ½
 */
export async function testBasicFunctionality(): Promise<void> {
  console.log('ğŸ§ª å¼€å§‹LLMæ¨¡å—é›†æˆæµ‹è¯•...\n');

  // æµ‹è¯•1: è·å–æ¨¡å‹æ˜ å°„
  console.log('ğŸ“‹ æµ‹è¯•1: è·å–æ¨¡å‹æ˜ å°„');
  const models = getModelMapping();
  console.log('å¯ç”¨æ¨¡å‹æ•°é‡:', Object.keys(models).length);
  console.log('æ¨¡å‹åˆ—è¡¨:', Object.keys(models).slice(0, 10), '...');
  
  // æµ‹è¯•2: è·å–æä¾›å•†ä¿¡æ¯
  console.log('\nğŸ¢ æµ‹è¯•2: è·å–æä¾›å•†ä¿¡æ¯');
  const providerInfo = getProviderInfo();
  console.log('å¯ç”¨æä¾›å•†:', providerInfo.available);
  console.log('æä¾›å•†ç»Ÿè®¡:', providerInfo.stats);

  // æµ‹è¯•3: æ£€æŸ¥æ¨ç†æ¨¡å‹
  console.log('\nğŸ§  æµ‹è¯•3: æ£€æŸ¥æ¨ç†æ¨¡å‹');
  const testModels = ['deepseek-chat', 'deepseek-reasoner', 'gpt-4.1', 'o3-mini', 'gpt-4o', 'gpt-4o-mini', 'gemini-2.5-pro-preview', 'gemini-2.5-flash-preview', 'gemini-2.0-flash', 'grok-3-latest', 'grok-3-mini-fast', 'grok-2-image'];
  for (const model of testModels) {
    const isReasoner = isReasoningModel(model);
    const supportsTools = modelSupportsTools(model);
    console.log(`  ${model}: æ¨ç†=${isReasoner}, å·¥å…·=${supportsTools}`);
  }

  // æµ‹è¯•4: æŒ‰æä¾›å•†åˆ†ç»„æ¨¡å‹
  console.log('\nğŸ”— æµ‹è¯•4: æŒ‰æä¾›å•†åˆ†ç»„æ¨¡å‹');
  const modelsByProvider = getModelsByProvider();
  for (const [provider, modelList] of Object.entries(modelsByProvider)) {
    console.log(`  ${provider}: ${modelList.length}ä¸ªæ¨¡å‹ - ${modelList.slice(0, 3).join(', ')}${modelList.length > 3 ? '...' : ''}`);
  }

  // æµ‹è¯•5: è·å–æ¨èæ¨¡å‹
  console.log('\nâ­ æµ‹è¯•5: è·å–æ¨èæ¨¡å‹');
  const recommended = getRecommendedModels();
  console.log('æ¨ç†æ¨¡å‹:', recommended.reasoning);
  console.log('é€šç”¨æ¨¡å‹:', recommended.general);
  console.log('è§†è§‰æ¨¡å‹:', recommended.vision.slice(0, 5));
  console.log('æ€§ä»·æ¯”æ¨¡å‹:', recommended.costEffective.slice(0, 3));

  console.log('\nâœ… åŸºç¡€åŠŸèƒ½æµ‹è¯•å®Œæˆ!');
}

/**
 * æµ‹è¯•OpenAIæä¾›å•†
 */
export async function testOpenAIProvider(): Promise<void> {
  console.log('\nğŸ¤– æµ‹è¯•OpenAIæä¾›å•†...');

  const openaiModels = ['gpt-4.1', 'o3-mini', 'gpt-4o', 'gpt-4o-mini'];
  
  for (const model of openaiModels) {
    console.log(`\næµ‹è¯•æ¨¡å‹: ${model}`);
    
    const modelInfo = getModelMapping()[model];
    if (!modelInfo) {
      console.log('  âŒ æ¨¡å‹ä¸å­˜åœ¨');
      continue;
    }

    console.log('  âœ… æ¨¡å‹å·²é…ç½®');
    console.log('  - æä¾›å•†:', modelInfo.provider);
    console.log('  - æ¨ç†æ¨¡å‹:', !!modelInfo.isReasoner);
    console.log('  - æ”¯æŒå·¥å…·:', !!modelInfo.supports?.tools);
    console.log('  - æ”¯æŒè§†è§‰:', !!modelInfo.supports?.vision);
    console.log('  - æœ€å¤§tokens:', modelInfo.supports?.max_tokens?.max || 'æœªçŸ¥');
  }
}

/**
 * æµ‹è¯•Geminiæä¾›å•†
 */
export async function testGeminiProvider(): Promise<void> {
  console.log('\nğŸŒŸ æµ‹è¯•Geminiæä¾›å•†...');

  const geminiModels = ['gemini-2.5-pro-preview', 'gemini-2.5-flash-preview', 'gemini-2.0-flash'];
  
  for (const model of geminiModels) {
    console.log(`\næµ‹è¯•æ¨¡å‹: ${model}`);
    
    const modelInfo = getModelMapping()[model];
    if (!modelInfo) {
      console.log('  âŒ æ¨¡å‹ä¸å­˜åœ¨');
      continue;
    }

    console.log('  âœ… æ¨¡å‹å·²é…ç½®');
    console.log('  - æä¾›å•†:', modelInfo.provider);
    console.log('  - æ¨ç†æ¨¡å‹:', !!modelInfo.isReasoner);
    console.log('  - æ”¯æŒå·¥å…·:', !!modelInfo.supports?.tools);
    console.log('  - æ”¯æŒè§†è§‰:', !!modelInfo.supports?.vision);
    console.log('  - æ”¯æŒæ–‡æ¡£:', !!modelInfo.supports?.documents);
    console.log('  - æœ€å¤§tokens:', modelInfo.supports?.max_tokens?.max || 'æœªçŸ¥');
    
    // æ£€æŸ¥æ€ç»´æ¨ç†é…ç½®
    if (modelInfo.supports?.thinking) {
      const thinking = modelInfo.supports.thinking;
      if (typeof thinking === 'object') {
        console.log('  - æ€ç»´æ¨ç†: æ”¯æŒï¼Œé¢„ç®—tokens:', thinking.budget_tokens);
      } else {
        console.log('  - æ€ç»´æ¨ç†:', thinking ? 'æ”¯æŒ' : 'ä¸æ”¯æŒ');
      }
    }
  }
}

/**
 * æµ‹è¯•xAIæä¾›å•†
 */
export async function testXAIProvider(): Promise<void> {
  console.log('\nğŸ¤– æµ‹è¯•xAI Grokæä¾›å•†...');

  const xaiModels = ['grok-3-latest', 'grok-3-mini-fast', 'grok-2-image'];
  
  for (const model of xaiModels) {
    console.log(`\næµ‹è¯•æ¨¡å‹: ${model}`);
    
    const modelInfo = getModelMapping()[model];
    if (!modelInfo) {
      console.log('  âŒ æ¨¡å‹ä¸å­˜åœ¨');
      continue;
    }

    console.log('  âœ… æ¨¡å‹å·²é…ç½®');
    console.log('  - æä¾›å•†:', modelInfo.provider);
    console.log('  - æ¨ç†æ¨¡å‹:', !!modelInfo.isReasoner);
    console.log('  - æ”¯æŒå·¥å…·:', !!modelInfo.supports?.tools);
    console.log('  - æ”¯æŒè§†è§‰:', !!modelInfo.supports?.vision);
    console.log('  - æ”¯æŒæœç´¢:', !!modelInfo.supports?.search);
    console.log('  - ç»“æ„åŒ–è¾“å‡º:', !!modelInfo.supports?.structured_output);
    console.log('  - æœ€å¤§tokens:', modelInfo.supports?.max_tokens?.max || 'æœªçŸ¥');
    
    // æ£€æŸ¥æ¨ç†åŠªåŠ›é…ç½®
    if (modelInfo.supports?.reasoning_effort) {
      const effort = modelInfo.supports.reasoning_effort;
      console.log('  - æ¨ç†åŠªåŠ›: æ”¯æŒï¼Œé€‰é¡¹:', effort.options?.join('/'), 'é»˜è®¤:', effort.default);
    }
    
    // æ£€æŸ¥å›¾åƒåŠŸèƒ½
    if (modelInfo.supports?.image_generation) {
      const imgGen = modelInfo.supports.image_generation;
      console.log('  - å›¾åƒç”Ÿæˆ: æ”¯æŒï¼Œæœ€å¤§:', imgGen.max_images, 'å¼ ');
    }
    
    if (modelInfo.supports?.image_input) {
      const imgInput = modelInfo.supports.image_input;
      console.log('  - å›¾åƒè¾“å…¥: æ”¯æŒï¼Œæœ€å¤§å°ºå¯¸:', imgInput.max_size_mb, 'MB');
    }
  }
}

/**
 * æµ‹è¯•æµå¼è°ƒç”¨ï¼ˆå¦‚æœæœ‰APIå¯†é’¥ï¼‰
 */
export async function testStreamCall(): Promise<void> {
  console.log('\nğŸŒŠ æµ‹è¯•æµå¼è°ƒç”¨...');

  const hasOpenAIKey = !!process.env.OPENAI_API_KEY;
  const hasDeepSeekKey = !!process.env.DEEPSEEK_API_KEY;
  const hasGeminiKey = !!(process.env.GEMINI_API_KEY || process.env.GOOGLE_API_KEY);
  const hasXAIKey = !!process.env.XAI_API_KEY;

  console.log('APIå¯†é’¥çŠ¶æ€:');
  console.log('  OpenAI:', hasOpenAIKey ? 'âœ… å·²é…ç½®' : 'âŒ æœªé…ç½®');
  console.log('  DeepSeek:', hasDeepSeekKey ? 'âœ… å·²é…ç½®' : 'âŒ æœªé…ç½®');
  console.log('  Gemini:', hasGeminiKey ? 'âœ… å·²é…ç½®' : 'âŒ æœªé…ç½®');
  console.log('  xAI:', hasXAIKey ? 'âœ… å·²é…ç½®' : 'âŒ æœªé…ç½®');

  if (!hasOpenAIKey && !hasDeepSeekKey && !hasGeminiKey && !hasXAIKey) {
    console.log('  âš ï¸ æ²¡æœ‰å¯ç”¨çš„APIå¯†é’¥ï¼Œè·³è¿‡å®é™…è°ƒç”¨æµ‹è¯•');
    return;
  }

  // é€‰æ‹©ä¸€ä¸ªå¯ç”¨çš„æ¨¡å‹è¿›è¡Œæµ‹è¯•
  let testModel: string;
  if (hasXAIKey) {
    testModel = 'grok-3-mini-fast';
  } else if (hasGeminiKey) {
    testModel = 'gemini-2.0-flash';
  } else if (hasOpenAIKey) {
    testModel = 'gpt-4o-mini';
  } else {
    testModel = 'deepseek-chat';
  }
  
  console.log(`\nä½¿ç”¨æ¨¡å‹ ${testModel} è¿›è¡Œæµå¼æµ‹è¯•...`);

  const request: LLMRequest = {
    model: testModel,
    messages: [
      { role: 'user', content: 'ç®€å•å›ç­”ï¼š1+1ç­‰äºå¤šå°‘ï¼Ÿ' }
    ],
    max_tokens: 50,
    temperature: 0.7
  };

  try {
    let response = '';
    await callLLMStream(request, (chunk, type) => {
      if (type === 'content_chunk') {
        const data = JSON.parse(chunk);
        if (data.content) {
          response += data.content;
          process.stdout.write(data.content);
        }
      }
    });
    
    console.log('\nâœ… æµå¼è°ƒç”¨æˆåŠŸï¼');
    console.log('å®Œæ•´å“åº”:', response.trim());
  } catch (error) {
    console.log('\nâŒ æµå¼è°ƒç”¨å¤±è´¥:', (error as Error).message);
  }
}

/**
 * æµ‹è¯•å¤šæä¾›å•†åŠŸèƒ½å¯¹æ¯”
 */
export async function testMultiProviderComparison(): Promise<void> {
  console.log('\nğŸ” æµ‹è¯•å¤šæä¾›å•†åŠŸèƒ½å¯¹æ¯”...');

  const models = getModelMapping();
  const providers = ['deepseek', 'openai', 'google', 'xai'];
  
  console.log('\nğŸ“Š åŠŸèƒ½æ”¯æŒå¯¹æ¯”:');
  console.log('æä¾›å•†\tæ¨¡å‹æ•°\tæ¨ç†æ¨¡å‹\tè§†è§‰æ¨¡å‹\tå·¥å…·æ¨¡å‹\tå›¾åƒç”Ÿæˆ\tæœç´¢æ”¯æŒ');
  console.log('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€');
  
  for (const provider of providers) {
    const providerModels = Object.entries(models).filter(([_, config]) => config.provider === provider);
    const modelCount = providerModels.length;
    const reasoningCount = providerModels.filter(([_, config]) => config.isReasoner).length;
    const visionCount = providerModels.filter(([_, config]) => config.supports?.vision).length;
    const toolsCount = providerModels.filter(([_, config]) => config.supports?.tools).length;
    const imageGenCount = providerModels.filter(([_, config]) => config.supports?.image_generation).length;
    const searchCount = providerModels.filter(([_, config]) => config.supports?.search).length;
    
    console.log(`${provider}\t${modelCount}\t${reasoningCount}\t\t${visionCount}\t\t${toolsCount}\t\t${imageGenCount}\t\t${searchCount}`);
  }
  
  console.log('\nğŸ† æ¨èæ¨¡å‹ç»„åˆ:');
  console.log('- å¤æ‚æ¨ç†: deepseek-reasoner, o3-mini (å¼ºæ¨ç†)');
  console.log('- é€šç”¨å¯¹è¯: deepseek-chat, gpt-4.1 (å¹³è¡¡æ€§èƒ½)');
  console.log('- å¤šæ¨¡æ€: gpt-4o, gemini-2.5-pro-preview (å›¾æ–‡ç†è§£)');
  console.log('- ç»æµé€‰æ‹©: gpt-4o-mini, gemini-2.0-flash (é«˜æ€§ä»·æ¯”)');
  console.log('- ä¼ä¸šåº”ç”¨: grok-3-latest (æ·±åº¦çŸ¥è¯†)');
  console.log('- å›¾åƒç”Ÿæˆ: grok-2-image (åˆ›æ„è®¾è®¡)');
}

/**
 * ä¸»æµ‹è¯•å‡½æ•°
 */
export async function runAllTests(): Promise<void> {
  try {
    await testBasicFunctionality();
    await testOpenAIProvider();
    await testGeminiProvider();
    await testXAIProvider();
    await testStreamCall();
    await testMultiProviderComparison();
    
    console.log('\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼');
    console.log('\nğŸ“ˆ æ¶æ„ä¼˜åŒ–æ€»ç»“:');
    console.log('âœ… æˆåŠŸå®ç°æ¨¡å—åŒ–LLMæä¾›å•†æ¶æ„');
    console.log('âœ… æ”¯æŒ DeepSeek + OpenAI + Gemini + xAI å››å¤§æä¾›å•†');
    console.log(`âœ… æ€»è®¡ ${Object.keys(getModelMapping()).length} ä¸ªæ¨¡å‹å¯ç”¨`);
    console.log('âœ… ç»Ÿä¸€APIæ¥å£ï¼Œæ”¯æŒæµå¼/éæµå¼è°ƒç”¨');
    console.log('âœ… å®Œæ•´çš„ç±»å‹å®šä¹‰å’Œå‚æ•°éªŒè¯');
    console.log('âœ… æ”¯æŒæ¨ç†æ¨¡å‹ã€å·¥å…·è°ƒç”¨ã€å¤šæ¨¡æ€ã€å›¾åƒç”Ÿæˆç­‰é«˜çº§åŠŸèƒ½');
    console.log('âœ… æ”¯æŒå®æ—¶æœç´¢ã€ç»“æ„åŒ–è¾“å‡ºç­‰å‰æ²¿åŠŸèƒ½');
  } catch (error) {
    console.error('\nğŸ’¥ æµ‹è¯•å¤±è´¥:', error);
    process.exit(1);
  }
}

// å¦‚æœç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶ï¼Œæ‰§è¡Œæµ‹è¯•
if (require.main === module) {
  runAllTests();
} 