// pages/index.tsx
// ä¸»é¡µï¼šAIå¤šæ¨¡å‹å¯¹è¯ä¸»ç•Œé¢ï¼ŒåŒ…å«æ¨¡å‹åˆ‡æ¢ã€å†å²ä¼šè¯ç®¡ç†ã€æµå¼å¯¹è¯ã€æ¶ˆæ¯æ¸²æŸ“ç­‰æ ¸å¿ƒåŠŸèƒ½ã€‚
import React, { useState, useRef, useEffect, useCallback } from 'react';
import Head from 'next/head';
import Sidebar from '../components/Sidebar';
import TopBar from '../components/TopBar';
import MessageList from '../components/MessageList';
import ChatInput, { UploadedFile } from '../components/ChatInput';
import ModelSelector from '../components/ModelSelector';
import AdvancedSettings from '../components/AdvancedSettings';
import { LLMRequest, getModelMapping } from '../utils/llm';
import { Message, ChatSession } from '../interfaces';
import { processDocument, analyzeFileSupport, ProcessingResult, ProcessingStatus } from '../utils/fileProcessing';
import { isReasoningModel } from '../utils/llm';

// ä½¿ç”¨æ–°çš„getModelMappingå‡½æ•°è·å–æ¨¡å‹æ˜ å°„
const MODEL_MAPPING = getModelMapping();

// Load sessions from localStorage
function loadSessions(): ChatSession[] {
  if (typeof window === 'undefined') return [];
  try {
    return JSON.parse(localStorage.getItem('chat_sessions') || '[]');
  } catch {
    return [];
  }
}

// Save sessions to localStorage
function saveSessions(sessions: ChatSession[]) {
  if (typeof window !== 'undefined') {
    try {
      const sessionsData = JSON.stringify(sessions);
      localStorage.setItem('chat_sessions', sessionsData);
    } catch (error: any) {
      if (error.name === 'QuotaExceededError') {
        console.warn('LocalStorage quota exceeded, attempting to clean up old sessions...');
        
        // å°è¯•æ¸…ç†ç­–ç•¥
        try {
          // 1. é¦–å…ˆåˆ é™¤å·²å½’æ¡£çš„ä¼šè¯
          const archivedSessions = sessions.filter(s => s.archived);
          if (archivedSessions.length > 0) {
            const cleanedSessions = sessions.filter(s => !s.archived);
            localStorage.setItem('chat_sessions', JSON.stringify(cleanedSessions));
            console.log(`Cleaned ${archivedSessions.length} archived sessions`);
            return;
          }
          
          // 2. å¦‚æœæ²¡æœ‰å½’æ¡£ä¼šè¯ï¼Œåˆ é™¤æœ€æ—§çš„éå½“å‰ä¼šè¯
          if (sessions.length > 10) {
            const sortedSessions = [...sessions].sort((a, b) => b.lastUpdated - a.lastUpdated);
            const recentSessions = sortedSessions.slice(0, 10);
            localStorage.setItem('chat_sessions', JSON.stringify(recentSessions));
            console.log(`Kept only ${recentSessions.length} most recent sessions`);
            return;
          }
          
          // 3. æœ€åæ‰‹æ®µï¼šæ¸…ç†ä¼šè¯ä¸­çš„é•¿æ¶ˆæ¯å†…å®¹
          const compactSessions = sessions.map(session => ({
            ...session,
            messages: session.messages.map(msg => ({
              ...msg,
              content: typeof msg.content === 'string' && msg.content.length > 1000 
                ? msg.content.substring(0, 1000) + '...[truncated]'
                : msg.content,
              thinking: msg.thinking && msg.thinking.length > 500 
                ? msg.thinking.substring(0, 500) + '...[truncated]'
                : msg.thinking
            }))
          }));
          localStorage.setItem('chat_sessions', JSON.stringify(compactSessions));
          console.log('Compacted session data by truncating long messages');
          
        } catch (retryError) {
          console.error('Failed to clean up localStorage:', retryError);
          // æ¸…ç†å¤±è´¥ï¼Œæ¸…ç©ºæ‰€æœ‰ä¼šè¯æ•°æ®
          localStorage.removeItem('chat_sessions');
          alert('å­˜å‚¨ç©ºé—´ä¸è¶³ï¼Œå·²æ¸…ç©ºå†å²ä¼šè¯ã€‚è¯·åˆ·æ–°é¡µé¢é‡æ–°å¼€å§‹ã€‚');
        }
      } else {
        console.error('Error saving sessions:', error);
      }
    }
  }
}

const DEFAULT_MODEL = 'deepseek-chat';

export default function HomePage() {
  const [sessions, setSessions] = useState<ChatSession[]>([]);
  const [currentSessionId, setCurrentSessionId] = useState<string | null>(null);
  const [model, setModel] = useState<LLMRequest['model']>(DEFAULT_MODEL);
  const [input, setInput] = useState('');
  const [isLoading, setIsLoading] = useState(false);
  const [uploadedImage, setUploadedImage] = useState<string | null>(null);
  const [uploadedFiles, setUploadedFiles] = useState<UploadedFile[]>([]);
  const [isSidebarOpen, setIsSidebarOpen] = useState(true);
  
  // Advanced settings state
  const [advancedSettings, setAdvancedSettings] = useState<{
    temperature?: number;
    top_p?: number;
    top_k?: number;
    max_tokens?: number;
    presence_penalty?: number;
    frequency_penalty?: number;
    stop_sequences?: string[];
    seed?: number;
    thinking?: { budget_tokens?: number; type?: string };
    system?: string;
  }>({});
  
  // æ£€æŸ¥API keyä»¥ç¡®å®šå“ªäº›æä¾›å•†åº”è¯¥è¢«ç¦ç”¨
  // åªæœ‰é…ç½®äº†API keyçš„æä¾›å•†æ‰ä¼šåœ¨UIä¸­å¯ç”¨
  const [disabledProviders, setDisabledProviders] = useState<string[]>([]);
  
  // Ref for the abort controller to cancel API requests
  const abortControllerRef = useRef<AbortController | null>(null);

  // Check for available API keys to update UI for disabled providers
  useEffect(() => {
    if (typeof window !== 'undefined') {
      try {
        const savedKeys = JSON.parse(localStorage.getItem('api_keys') || '{}');
        const newDisabled: string[] = [];
        
        // æä¾›å•†åç§°åˆ°è®¾ç½®é”®çš„æ˜ å°„ï¼ˆä¸getApiKeyForProviderä¿æŒä¸€è‡´ï¼‰
        const providerToSettingsKey: { [key: string]: string } = {
          'openai': 'gpt',
          'anthropic': 'claude', 
          'google': 'gemini',
          'deepseek': 'deepseek',
          'xai': 'grok'
        };
        
        // æ£€æŸ¥æ¯ä¸ªæä¾›å•†çš„API keyï¼Œå¦‚æœæ²¡æœ‰åˆ™ç¦ç”¨
        Object.entries(providerToSettingsKey).forEach(([provider, settingsKey]) => {
          if (!savedKeys[settingsKey]) {
            newDisabled.push(provider);
          }
        });
        
        setDisabledProviders(newDisabled);

        // æ£€æŸ¥localStorageä½¿ç”¨æƒ…å†µ
        try {
          const sessionsData = localStorage.getItem('chat_sessions');
          if (sessionsData) {
            const sizeInBytes = new Blob([sessionsData]).size;
            const sizeInMB = sizeInBytes / (1024 * 1024);
            
            // ä¼°ç®—localStorageé…é¢ï¼ˆé€šå¸¸æ˜¯5-10MBï¼‰
            const estimatedQuotaMB = 5;
            const usagePercentage = (sizeInMB / estimatedQuotaMB) * 100;
            
            console.log(`ğŸ“Š LocalStorage usage: ${sizeInMB.toFixed(2)}MB (${usagePercentage.toFixed(1)}%)`);
            
            // å½“ä½¿ç”¨è¶…è¿‡80%æ—¶è­¦å‘Šç”¨æˆ·
            if (usagePercentage > 80) {
              console.warn('âš ï¸ LocalStorage usage high, consider clearing old sessions');
              
              // å½“ä½¿ç”¨è¶…è¿‡90%æ—¶æ˜¾ç¤ºç”¨æˆ·æç¤º
              if (usagePercentage > 90) {
                setTimeout(() => {
                  const shouldClean = confirm(
                    `å­˜å‚¨ç©ºé—´ä½¿ç”¨ç‡å·²è¾¾ ${usagePercentage.toFixed(1)}%\n\n` +
                    `ä¸ºäº†é¿å…æ•°æ®ä¸¢å¤±ï¼Œå»ºè®®æ¸…ç†ä¸€äº›æ—§çš„ä¼šè¯è®°å½•ã€‚\n\n` +
                    `æ˜¯å¦ç°åœ¨æ¸…ç†å·²å½’æ¡£çš„ä¼šè¯ï¼Ÿ`
                  );
                  
                  if (shouldClean) {
                    const currentSessions = JSON.parse(localStorage.getItem('chat_sessions') || '[]');
                    const cleanedSessions = currentSessions.filter((s: ChatSession) => !s.archived);
                    localStorage.setItem('chat_sessions', JSON.stringify(cleanedSessions));
                    location.reload(); // åˆ·æ–°é¡µé¢ä»¥åŠ è½½æ¸…ç†åçš„æ•°æ®
                  }
                }, 1000);
              }
            }
          }
        } catch (storageError) {
          console.error('Error checking localStorage usage:', storageError);
        }
        
      } catch (error) {
        console.error('Error reading API keys from localStorage for UI disable state:', error);
        // å¦‚æœlocalStorageæŸåï¼Œç¦ç”¨æ‰€æœ‰æä¾›å•†
        setDisabledProviders(['openai', 'anthropic', 'google', 'xai']);
      }
    }
  }, []);

  // Load saved sessions on initial load
  useEffect(() => {
    const savedSessions = loadSessions();
    if (savedSessions.length > 0) {
      setSessions(savedSessions);
      // Set the most recent session as current
      const sortedSessions = [...savedSessions].sort((a, b) => b.lastUpdated - a.lastUpdated);
      const activeSession = sortedSessions.find(s => !s.archived) || sortedSessions[0];
      setCurrentSessionId(activeSession.id);
      setModel(activeSession.model || DEFAULT_MODEL);
    } else {
      handleNewSession(); // Create a new session if none exist
    }
  // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []);

  // Save sessions whenever they change
  useEffect(() => {
    if (sessions.length > 0) {
      saveSessions(sessions);
    }
  }, [sessions]);

  // Current active session
  const currentSession = sessions.find(s => s.id === currentSessionId);

  // Update messages in the current session
  const updateSessionMessages = (messages: Message[]) => {
    if (currentSessionId) {
      setSessions(prevSessions =>
        prevSessions.map(s =>
          s.id === currentSessionId
            ? { ...s, messages, lastUpdated: Date.now() }
            : s
        )
      );
    }
  };
  
  // Add a new message to the current session
  const addMessageToCurrentSession = (message: Message) => {
    if (currentSessionId) {
      setSessions(prevSessions =>
        prevSessions.map(s =>
          s.id === currentSessionId
            ? { ...s, messages: [...s.messages, message], lastUpdated: Date.now() }
            : s
        )
      );
    }
  };

  // Add a specific assistantMessage update to support thinking state
  const updateAssistantMessage = (sessionId: string, messageId: string, content: string, thinking?: string, isThinking: boolean = false) => {
    setSessions(prevSessions =>
      prevSessions.map(s =>
        s.id === sessionId
          ? {
              ...s,
              messages: s.messages.map(m =>
                m.id === messageId
                  ? { ...m, content, thinking, isThinking }
                  : m
              ),
              lastUpdated: Date.now()
            }
          : s
      )
    );
  };

  // Create a new chat session
  const handleNewSession = useCallback(() => {
    const newSessionId = `session-${Date.now()}`;
    const newSession: ChatSession = {
      id: newSessionId,
      name: 'New Chat',
      messages: [],
      model: model,
      lastUpdated: Date.now(),
      archived: false
    };
    setSessions(prevSessions => [...prevSessions, newSession]);
          setCurrentSessionId(newSessionId);
      setInput('');
      setUploadedImage(null);
      setUploadedFiles([]);
  }, [model]);

  // Switch to an existing session
  const handleSwitchSession = (sessionId: string) => {
    const switchedSession = sessions.find(s => s.id === sessionId);
    if (switchedSession) {
      setCurrentSessionId(sessionId);
      setModel(switchedSession.model || DEFAULT_MODEL);
      setInput('');
      setUploadedImage(null);
      setUploadedFiles([]);
    }
  };

  // Archive/Unarchive a session
  const handleArchiveSession = (sessionId: string) => {
    setSessions(prevSessions =>
      prevSessions.map(s =>
        s.id === sessionId
          ? { ...s, archived: !s.archived }
          : s
      )
    );
  };

  // Delete a session
  const handleDeleteSession = (sessionId: string) => {
    setSessions(prevSessions => prevSessions.filter(s => s.id !== sessionId));
    
    // If we deleted the current session, switch to another one
    if (sessionId === currentSessionId) {
      const remainingSessions = sessions.filter(s => s.id !== sessionId);
      if (remainingSessions.length > 0) {
        const activeSessions = remainingSessions.filter(s => !s.archived);
        const nextSession = activeSessions.length > 0 ? activeSessions[0] : remainingSessions[0];
        setCurrentSessionId(nextSession.id);
        setModel(nextSession.model || DEFAULT_MODEL);
      } else {
        // No sessions left, create a new one
        handleNewSession();
      }
    }
  };

  // Batch delete sessions
  const handleBatchDeleteSessions = (sessionIds: string[]) => {
    if (sessionIds.length === 0) return;

    setSessions(prevSessions => {
      const filteredSessions = prevSessions.filter(s => !sessionIds.includes(s.id));
      
      // If current session was deleted, switch to another one
      if (sessionIds.includes(currentSessionId || '')) {
        if (filteredSessions.length > 0) {
          const activeSessions = filteredSessions.filter(s => !s.archived);
          const nextSession = activeSessions.length > 0 ? activeSessions[0] : filteredSessions[0];
          setTimeout(() => {
            setCurrentSessionId(nextSession.id);
            setModel(nextSession.model || DEFAULT_MODEL);
          }, 0);
        } else {
          // No sessions left, create a new one
          setTimeout(() => {
            handleNewSession();
          }, 0);
        }
      }
      
      return filteredSessions;
    });

    console.log(`âœ… æ‰¹é‡åˆ é™¤äº† ${sessionIds.length} ä¸ªä¼šè¯`);
  };

  // Automatically summarize the conversation title
  const summarizeTitle = async (sessionId: string, messages: Message[]) => {
    if (messages.length < 2 || messages.length > 10) return; // Only summarize for reasonable length convos
    const conversationText = messages.slice(0, 5).map(m => `${m.role}: ${m.content}`).join('\n');
    
    // ğŸ”§ ä¼˜åŒ–ï¼šä½¿ç”¨DeepSeek JSONè¾“å‡ºåŠŸèƒ½ï¼Œæä¾›ç»“æ„åŒ–çš„prompt
    const prompt = `Please analyze the following conversation and generate a concise title in JSON format.

CONVERSATION:
${conversationText}

Please output your response in JSON format with the following structure:

EXAMPLE JSON OUTPUT:
{
  "title": "Quantum Computing Basics",
  "description": "Discussion about quantum computing principles"
}

Requirements:
- title: Maximum 5 words, concise and descriptive
- description: Brief summary of the conversation topic
- Output must be valid JSON format`;
    
    // ğŸ”§ ä¿®å¤ï¼šè·å–DeepSeek APIå¯†é’¥
    const deepseekApiKey = getApiKeyForProvider('deepseek');
    if (!deepseekApiKey) {
      console.warn('DeepSeek APIå¯†é’¥æœªé…ç½®ï¼Œè·³è¿‡æ ‡é¢˜æ€»ç»“');
      return;
    }

    // Get network options to pass to the API
    const currentNetworkOptions = getNetworkOptions();
    console.log('Using title summarization with JSON output, options:', currentNetworkOptions);

    try {
      const response = await fetch('/api/chat', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: 'deepseek-chat', // Use DeepSeek for fast and reliable title generation
          messages: [{ role: 'user', content: prompt }],
          stream: false,
          temperature: 0.3, // ğŸ”§ ä¼˜åŒ–ï¼šé™ä½æ¸©åº¦ä»¥è·å¾—æ›´ä¸€è‡´çš„JSONè¾“å‡º
          max_tokens: 100, // ğŸ”§ ä¼˜åŒ–ï¼šå¢åŠ tokenæ•°é‡ä»¥å®¹çº³JSONç»“æ„
          response_format: { type: 'json_object' }, // ğŸ”§ æ–°å¢ï¼šå¯ç”¨JSONè¾“å‡ºæ¨¡å¼
          apiKey: deepseekApiKey, // ğŸ”§ ä¿®å¤ï¼šæ·»åŠ APIå¯†é’¥
          api_options: currentNetworkOptions
        }),
      });
      
      if (!response.ok) {
        console.error('Title summarization failed with status:', response.status);
        const errorText = await response.text();
        console.error('Error details:', errorText);
        return;
      }
      
      const data = await response.json();
      console.log('Title summarization JSON response:', data);
      
      // ğŸ”§ ä¼˜åŒ–ï¼šè§£æJSONæ ¼å¼çš„å“åº”
      if (data.title && typeof data.title === 'string') {
        const titleText = data.title.trim();
        console.log('âœ… ä»titleå­—æ®µè·å–æ ‡é¢˜:', titleText);
        setSessions(prevSessions =>
          prevSessions.map(s => (s.id === sessionId ? { ...s, name: titleText } : s))
        );
      } else if (data.content && typeof data.content === 'string') {
        // è§£æcontentå­—æ®µä¸­çš„JSON
        try {
          const contentJson = JSON.parse(data.content);
          if (contentJson.title && typeof contentJson.title === 'string') {
            const titleText = contentJson.title.trim();
            console.log('âœ… ä»contentä¸­çš„JSONè·å–æ ‡é¢˜:', titleText);
            setSessions(prevSessions =>
              prevSessions.map(s => (s.id === sessionId ? { ...s, name: titleText } : s))
            );
          } else {
            // å¦‚æœJSONè§£æå¤±è´¥ï¼Œä½¿ç”¨contentçš„å‰30ä¸ªå­—ç¬¦ä½œä¸ºæ ‡é¢˜
            const fallbackTitle = data.content.trim().substring(0, 30);
            console.log('âš ï¸ JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨fallbackæ ‡é¢˜:', fallbackTitle);
            setSessions(prevSessions =>
              prevSessions.map(s => (s.id === sessionId ? { ...s, name: fallbackTitle } : s))
            );
          }
        } catch (jsonError) {
          console.error('âŒ JSONè§£æå¤±è´¥:', jsonError);
          // å¦‚æœcontentæœ¬èº«å°±åŒ…å«JSONæ ¼å¼ï¼Œå°è¯•ç›´æ¥æå–title
          const titleMatch = data.content.match(/"title"\s*:\s*"([^"]+)"/);
          if (titleMatch) {
            const titleText = titleMatch[1].trim();
            console.log('âœ… ä»æ­£åˆ™åŒ¹é…è·å–æ ‡é¢˜:', titleText);
            setSessions(prevSessions =>
              prevSessions.map(s => (s.id === sessionId ? { ...s, name: titleText } : s))
            );
          } else {
            // ä½¿ç”¨contentçš„å‰30ä¸ªå­—ç¬¦ä½œä¸ºæ ‡é¢˜
            const fallbackTitle = data.content.trim().substring(0, 30);
            console.log('âš ï¸ ä½¿ç”¨fallbackæ ‡é¢˜:', fallbackTitle);
            setSessions(prevSessions =>
              prevSessions.map(s => (s.id === sessionId ? { ...s, name: fallbackTitle } : s))
            );
          }
        }
      } else {
        console.error('âŒ å“åº”ä¸­æ²¡æœ‰æ‰¾åˆ°titleæˆ–contentå­—æ®µ');
      }
    } catch (error) {
      console.error('Error summarizing title:', error);
    }
  };

  // Let's update the handleSend function and regenerateMessage function to add API keys to requests
  const getApiKeyForProvider = (providerName: string): string | undefined => {
    if (typeof window !== 'undefined') {
      try {
        // æä¾›å•†åç§°åˆ°è®¾ç½®é”®çš„æ˜ å°„
        const providerToSettingsKey: { [key: string]: string } = {
          'openai': 'gpt',
          'anthropic': 'claude', 
          'google': 'gemini',
          'deepseek': 'deepseek',
          'xai': 'grok'
        };
        
        const settingsKey = providerToSettingsKey[providerName] || providerName;
        const savedKeys = JSON.parse(localStorage.getItem('api_keys') || '{}');
        const apiKey = savedKeys[settingsKey];
        
        console.log(`[API Key Debug] Provider: ${providerName}, Settings Key: ${settingsKey}, Has Key: ${!!apiKey}`);
        
        return apiKey;
      } catch (error) {
        console.error('Error reading API keys:', error);
      }
    }
    return undefined;
  };

  // è·å–ç½‘ç»œè®¾ç½®é€‰é¡¹
  const getNetworkOptions = (): { skipConnectionCheck: boolean, bypassProxy: boolean } => {
    if (typeof window !== 'undefined') {
      try {
        const savedOptions = JSON.parse(localStorage.getItem('api_options') || '{}');
        return {
          skipConnectionCheck: true, // Always skip connection check
          bypassProxy: savedOptions.bypassProxy || false
        };
      } catch (error) {
        console.error('Error reading network options:', error);
      }
    }
    return { skipConnectionCheck: true, bypassProxy: false }; // Default to skip if localStorage fails
  };

  // Add API key and network options to the request
  const addApiKeyToRequest = (req: LLMRequest): LLMRequest => {
    const modelInfo = MODEL_MAPPING[req.model];
    if (!modelInfo) return req;
    
    // æ·»åŠ APIå¯†é’¥
    const apiKey = getApiKeyForProvider(modelInfo.provider);
    let updatedReq = { ...req };
    if (apiKey) {
      updatedReq.apiKey = apiKey;
    }
    
    // æ·»åŠ ç½‘ç»œè®¾ç½®é€‰é¡¹
    const networkOptions = getNetworkOptions();
    updatedReq.api_options = networkOptions;
    
    return updatedReq;
  };

  // More substantially update the handleSend function to better handle thinking state
  const handleSend = async () => {
    if (!input.trim() && !uploadedImage) return;
    if (!currentSessionId || !currentSession) {
      console.error("No current session to send message to.");
      return;
    }

    setIsLoading(true);
    
    // Create and add user message
    const userMessage: Message = {
      id: `msg-${Date.now()}`,
      role: 'user',
      content: input,
      ...(uploadedImage && { imageUrl: uploadedImage }),
    };

    // å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶å’Œå›¾ç‰‡
    let messageContent: string | any = input;
    
    // æ·»åŠ æ–‡ä»¶å†…å®¹åˆ°æ¶ˆæ¯ä¸­
    if (uploadedFiles.length > 0) {
      let additionalContent = '';
      const imageFiles = uploadedFiles.filter(f => f.type.startsWith('image/'));
      const textFiles = uploadedFiles.filter(f => f.content && !f.fileId && !f.fileUri);
      const nativeDocFiles = uploadedFiles.filter(f => f.fileId || f.fileUri);
      const otherFiles = uploadedFiles.filter(f => !f.type.startsWith('image/') && !f.content && !f.fileId && !f.fileUri);
      
      // å¤„ç†æ–‡æœ¬æ–‡ä»¶
      if (textFiles.length > 0) {
        additionalContent += '\n\n--- ä¸Šä¼ çš„æ–‡ä»¶å†…å®¹ ---\n';
        textFiles.forEach(file => {
          additionalContent += `\n[æ–‡ä»¶: ${file.name}]\n${file.content}\n`;
        });
      }
      
      // å¤„ç†åŸç”Ÿæ–‡æ¡£æ–‡ä»¶ï¼ˆå·²ä¸Šä¼ åˆ°APIçš„æ–‡ä»¶ï¼‰
      if (nativeDocFiles.length > 0) {
        const modelInfo = MODEL_MAPPING[model];
        if (modelInfo?.supports?.documents) {
          // å¯¹äºæ”¯æŒåŸç”Ÿæ–‡æ¡£å¤„ç†çš„æ¨¡å‹ï¼Œéœ€è¦æ ¹æ®ä¸åŒæä¾›å•†å¤„ç†æ–‡ä»¶å¼•ç”¨
          if (modelInfo.provider === 'google') {
            // Geminiéœ€è¦ä½¿ç”¨fileDataæ ¼å¼ï¼Œè€Œä¸æ˜¯åœ¨æ–‡æœ¬ä¸­å¼•ç”¨
            const fileDataParts = nativeDocFiles.filter(f => f.fileUri).map(file => ({
              fileData: {
                mimeType: file.type || 'application/pdf',
                fileUri: file.fileUri
              }
            }));
            
            // æ„å»ºå¤šæ¨¡æ€æ¶ˆæ¯å†…å®¹
            if (fileDataParts.length > 0) {
              messageContent = [
                { type: 'text', text: input },
                ...fileDataParts
              ];
            } else {
              // å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„fileUriï¼Œä»ç„¶ä½¿ç”¨æ–‡æœ¬æ–¹å¼
              additionalContent += '\n\n--- å·²ä¸Šä¼ æ–‡æ¡£ ---\n';
              nativeDocFiles.forEach(file => {
                if (file.fileUri) {
                  additionalContent += `[Geminiæ–‡ä»¶: ${file.name}, URI: ${file.fileUri}]\n`;
                }
              });
              messageContent = input + additionalContent;
            }
          } else if (modelInfo.provider === 'openai') {
            // OpenAIä½¿ç”¨ä¸åŒçš„æ–‡ä»¶å¼•ç”¨æ ¼å¼
            additionalContent += '\n\n--- å·²ä¸Šä¼ æ–‡æ¡£ ---\n';
            nativeDocFiles.forEach(file => {
              if (file.fileId) {
                additionalContent += `[OpenAIæ–‡ä»¶: ${file.name}, ID: ${file.fileId}]\n`;
              }
            });
            messageContent = input + additionalContent;
          } else {
            // å…¶ä»–æä¾›å•†çš„å¤„ç†
            additionalContent += '\n\n--- å·²ä¸Šä¼ æ–‡æ¡£ ---\n';
            nativeDocFiles.forEach(file => {
              if (file.fileId) {
                additionalContent += `[${modelInfo.provider}æ–‡ä»¶: ${file.name}, ID: ${file.fileId}]\n`;
              } else if (file.fileUri) {
                additionalContent += `[${modelInfo.provider}æ–‡ä»¶: ${file.name}, URI: ${file.fileUri}]\n`;
              }
            });
            messageContent = input + additionalContent;
          }
        } else {
          // å¦‚æœæ¨¡å‹ä¸æ”¯æŒï¼Œæ˜¾ç¤ºè­¦å‘Š
          additionalContent += '\n\n--- æ–‡æ¡£ä¸Šä¼ è­¦å‘Š ---\n';
          nativeDocFiles.forEach(file => {
            additionalContent += `[è­¦å‘Š: ${file.name} å·²ä¸Šä¼ ä½†å½“å‰æ¨¡å‹ä¸æ”¯æŒåŸç”Ÿæ–‡æ¡£å¤„ç†]\n`;
          });
          messageContent = input + additionalContent;
        }
      }
      
      // å¤„ç†å…¶ä»–æ–‡ä»¶
      if (otherFiles.length > 0) {
        additionalContent += '\n\n--- å…¶ä»–ä¸Šä¼ æ–‡ä»¶ ---\n';
        otherFiles.forEach(file => {
          additionalContent += `[æ–‡ä»¶: ${file.name}, ç±»å‹: ${file.type}, å¤§å°: ${(file.size / 1024).toFixed(2)}KB]\n`;
        });
      }
      
      // å¤„ç†å›¾ç‰‡
      if (imageFiles.length > 0) {
        const modelInfo = MODEL_MAPPING[model];
        if (modelInfo?.supports?.vision) {
          // å¯¹äºæ”¯æŒè§†è§‰çš„æ¨¡å‹ï¼Œä½¿ç”¨å¤šæ¨¡æ€æ ¼å¼
          const contentParts: any[] = [{ type: 'text', text: input + additionalContent }];
          imageFiles.forEach(file => {
            if (file.url) {
              contentParts.push({ type: 'image_url', image_url: { url: file.url } });
            }
          });
          messageContent = contentParts;
        } else {
          // å¯¹äºä¸æ”¯æŒè§†è§‰çš„æ¨¡å‹ï¼Œæ·»åŠ æç¤ºä¿¡æ¯
          additionalContent += '\n\n[æ³¨æ„ï¼šå½“å‰æ¨¡å‹ä¸æ”¯æŒå›¾åƒç†è§£ï¼Œå·²ä¸Šä¼ å›¾ç‰‡ä½†æ— æ³•åˆ†æ]';
          messageContent = input + additionalContent;
        }
      } else {
        messageContent = input + additionalContent;
      }
    } else if (uploadedImage) {
      // å‘åå…¼å®¹æ—§çš„å›¾ç‰‡ä¸Šä¼ æ–¹å¼
      const modelInfo = MODEL_MAPPING[model];
      if (modelInfo?.supports?.vision) {
        messageContent = [
          { type: 'text', text: input },
          { type: 'image_url', image_url: { url: uploadedImage } }
        ];
      } else {
        messageContent = input + '\n\n[æ³¨æ„ï¼šå½“å‰æ¨¡å‹ä¸æ”¯æŒå›¾åƒç†è§£ï¼Œå›¾ç‰‡å·²ä¸Šä¼ ä½†æ— æ³•åˆ†æ]';
      }
    }
    
    addMessageToCurrentSession(userMessage);
    setInput('');
    setUploadedImage(null);
    setUploadedFiles([]);

    // Create initial assistant message with thinking state
    const assistantMessageId = `msg-${Date.now()}-assistant`;
    const assistantMessagePlaceholder: Message = {
      id: assistantMessageId,
      role: 'assistant',
      content: '',
      thinking: '', // Initial empty thinking content
      isThinking: true, // Indicate that thinking is in progress
    };
    
    // Add the assistant message with initial thinking state
    addMessageToCurrentSession(assistantMessagePlaceholder);

    abortControllerRef.current = new AbortController();
    let accumulatedResponse = '';
    let reasoningBuffer = ''; // Start with empty reasoning buffer

    try {
      const response = await fetch('/api/chat', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        signal: abortControllerRef.current.signal,
        body: JSON.stringify(
          addApiKeyToRequest({
            model: currentSession.model || model,
            messages: [
              ...currentSession.messages.filter(m => m.id !== assistantMessageId)
                .map(m => ({ role: m.role, content: m.content })),
              { role: 'user', content: messageContent }
            ],
            stream: true,
            ...advancedSettings,
          } as LLMRequest)
        ),
      });

      if (!response.ok || !response.body) {
        throw new Error(`API Error: ${response.status} ${response.statusText}`);
      }

      // æ·»åŠ æµè§ˆå™¨å…¼å®¹æ€§æ£€æŸ¥
      if (!response.body.getReader) {
        throw new Error('ReadableStream not supported in this environment');
      }

      const reader = response.body.getReader();
      const decoder = new TextDecoder();
      let sseBuffer = ''; // NEW buffer to handle partial SSE chunks
      // eslint-disable-next-line no-constant-condition
      while (true) {
        const { value, done } = await reader.read();
        if (done) {
          if (!isLoading) break; // Already handled by finish_reason or error
          
          // Final update when stream is done - mark thinking as complete
          updateAssistantMessage(currentSessionId, assistantMessageId, accumulatedResponse, reasoningBuffer, false);
          
          setIsLoading(false);
          if (currentSessionId && currentSession && currentSession.messages.length > 0) {
            summarizeTitle(currentSessionId, currentSession.messages);
          }
          break;
        }

        const chunkText = decoder.decode(value, { stream: true });
        sseBuffer += chunkText; // append new chunk to buffer

        let delimiterIndex;
        while ((delimiterIndex = sseBuffer.indexOf('\n\n')) !== -1) {
          const eventText = sseBuffer.slice(0, delimiterIndex);
          sseBuffer = sseBuffer.slice(delimiterIndex + 2); // keep rest

          if (!eventText.startsWith('data: ')) continue;
          const jsonData = eventText.substring(6).trim();

          if (jsonData === '[DONE]' || jsonData.includes('"type":"done_event"')) {
            updateAssistantMessage(currentSessionId, assistantMessageId, accumulatedResponse, reasoningBuffer, false);
            setIsLoading(false);
            if (currentSessionId && currentSession && currentSession.messages.length > 0) {
              summarizeTitle(currentSessionId, currentSession.messages);
            }
            return;
          }

          try {
            const parsedSSE = JSON.parse(jsonData);
            
            // Handle direct thinking data from Gemini (new format)
            if (parsedSSE.thinking) {
              // Geminiæ€è€ƒå†…å®¹ç›´æ¥å¤„ç†
              reasoningBuffer += `${parsedSSE.thinking}\n`;
              updateAssistantMessage(currentSessionId, assistantMessageId, accumulatedResponse, reasoningBuffer, true);
            } else if (parsedSSE.content) {
              // Regular content to display in the message
              accumulatedResponse += parsedSSE.content;
              
              // Update the message with new content, preserve thinking state
              updateAssistantMessage(currentSessionId, assistantMessageId, accumulatedResponse, reasoningBuffer, true);
            } else if (parsedSSE.reasoning_content) {
              // Add reasoning content to the reasoning buffer
              reasoningBuffer += parsedSSE.reasoning_content + "\n";
              
              // Update the message with new thinking content but keep isThinking true
              updateAssistantMessage(currentSessionId, assistantMessageId, accumulatedResponse, reasoningBuffer, true);
            } else if (parsedSSE.error) {
              console.error("SSE Error Chunk:", parsedSSE.error, parsedSSE.details);
              accumulatedResponse += `\n\n[Error: ${parsedSSE.error}]`;
              
              // Update with error and mark thinking as complete
              updateAssistantMessage(
                currentSessionId, 
                assistantMessageId, 
                accumulatedResponse, 
                reasoningBuffer + `Error: ${parsedSSE.error}\n`, 
                false
              );
              
              setIsLoading(false);
              return; // Stop processing on error
            } else if (parsedSSE.finish_reason) {
              // When we get a finish reason, mark thinking as complete
              updateAssistantMessage(currentSessionId, assistantMessageId, accumulatedResponse, reasoningBuffer, false);
              
              setIsLoading(false);
              if (currentSessionId && currentSession && currentSession.messages.length > 0) {
                summarizeTitle(currentSessionId, currentSession.messages);
              }
            } else {
              // Legacy format handling with {type, data}
              const { type: stepType, data: eventData } = parsedSSE;
              
              if (eventData && eventData.error) {
                console.error("SSE Error Chunk:", eventData.error, eventData.details);
                accumulatedResponse += `\n\n[Error: ${eventData.error}]`;
                
                // Update with error and mark thinking as complete
                updateAssistantMessage(
                  currentSessionId, 
                  assistantMessageId, 
                  accumulatedResponse, 
                  reasoningBuffer + `Error: ${eventData.error}\n`, 
                  false
                );
                
                setIsLoading(false);
                return; // Stop processing on error
              }

              // Process different types of chunks
              if (stepType === 'thinking_step' && eventData.thinking) {
                // Geminiçš„æ€è€ƒå†…å®¹ï¼ˆä½¿ç”¨thinkingå­—æ®µï¼‰
                reasoningBuffer += `${eventData.thinking}\n`;
                
                // Update the message with new thinking content but keep isThinking true
                updateAssistantMessage(currentSessionId, assistantMessageId, accumulatedResponse, reasoningBuffer, true);
              } else if (stepType === 'thinking_step' && eventData.content) {
                // Add to reasoning buffer when we get thinking steps
                reasoningBuffer += `${eventData.content}\n`;
                
                // Update the message with new thinking content but keep isThinking true
                updateAssistantMessage(currentSessionId, assistantMessageId, accumulatedResponse, reasoningBuffer, true);
              } else if (stepType === 'thinking_step' && eventData.reasoning_content) {
                // Add to reasoning buffer when we get reasoning content
                reasoningBuffer += `${eventData.reasoning_content}\n`;
                
                // Update the message with new thinking content but keep isThinking true
                updateAssistantMessage(currentSessionId, assistantMessageId, accumulatedResponse, reasoningBuffer, true);
              } else if (stepType === 'step' && eventData.content) {
                // DeepSeek reasoner's steps
                reasoningBuffer += `Step: ${eventData.content}\n`;
                
                // Update the message with new thinking content
                updateAssistantMessage(currentSessionId, assistantMessageId, accumulatedResponse, reasoningBuffer, true);
                
              } else if (stepType === 'tool_use_step' && eventData) {
                // Format tool use information for reasoning display
                let toolInfo = 'Tool Invocation:\n';
                if(eventData.tool_name) toolInfo += `  Name: ${eventData.tool_name}\n`;
                if(eventData.tool_id) toolInfo += `  ID: ${eventData.tool_id}\n`;
                if(eventData.tool_input) toolInfo += `  Input: ${JSON.stringify(eventData.tool_input, null, 2)}\n`;
                if(eventData.tool_arguments) toolInfo += `  Arguments: ${JSON.stringify(eventData.tool_arguments, null, 2)}\n`;
                if(eventData.tool_arguments_raw) toolInfo += `  Arguments (raw): ${eventData.tool_arguments_raw}\n`;
                
                reasoningBuffer += toolInfo;
                
                // Update the message with new thinking content
                updateAssistantMessage(currentSessionId, assistantMessageId, accumulatedResponse, reasoningBuffer, true);
                
              } else if (stepType === 'content_chunk' && eventData.content) {
                // Regular content to display in the message
                accumulatedResponse += eventData.content;
                
                // Update the message with new content, preserve thinking state
                updateAssistantMessage(currentSessionId, assistantMessageId, accumulatedResponse, reasoningBuffer, true);
              } else if (stepType === 'image_data') {
                console.log('Received image_data chunk:', eventData.content);
                // This is AI-generated image data
                const parsedImageData = JSON.parse(eventData.content);
                if (parsedImageData.image_data) {
                  // Find the last assistant message and update it with image data
                  setSessions(prevSessions =>
                    prevSessions.map(s => {
                      if (s.id === currentSessionId) {
                        const lastMsgIndex = s.messages.length - 1;
                        if (lastMsgIndex >= 0 && s.messages[lastMsgIndex].role === 'assistant') {
                          const updatedMessages = [...s.messages];
                          updatedMessages[lastMsgIndex] = {
                            ...updatedMessages[lastMsgIndex],
                            aiImageData: parsedImageData.image_data,
                            isThinking: false // Image received, no longer just thinking
                          };
                          return { ...s, messages: updatedMessages, lastUpdated: Date.now() };
                        }
                      }
                      return s;
                    })
                  );
                }
              }
            }
          } catch (e) {
            console.error('Error parsing SSE JSON data:', jsonData, e);
          }
        }
      }
    } catch (error: any) {
      if (error.name === 'AbortError') {
        console.log('Request aborted by user.');
        // Update message to show cancelled state
        updateAssistantMessage(
          currentSessionId, 
          assistantMessageId, 
          "[Cancelled by user]", 
          reasoningBuffer + "\nRequest Cancelled by User.\n", 
          false
        );
      } else {
        console.error('Error sending message:', error);
        console.error('Error details:', {
          name: error.name,
          message: error.message,
          stack: error.stack,
          userAgent: navigator.userAgent,
          uploadedFilesCount: uploadedFiles.length,
          hasUploadedImage: !!uploadedImage
        });
        const errorMessage = `Error: ${error.message || 'Failed to get response.'}`;
        
        // Update message with error and mark thinking as complete
        updateAssistantMessage(
          currentSessionId, 
          assistantMessageId, 
          errorMessage, 
          reasoningBuffer + errorMessage + `\n`, 
          false
        );
      }
      setIsLoading(false);
    }
  };
  
  const handleCancel = () => {
    if (abortControllerRef.current) {
      abortControllerRef.current.abort();
      abortControllerRef.current = null;
      setIsLoading(false);
      
      // Update the last assistant message to indicate cancellation
      if (currentSessionId && currentSession) {
        const lastMessage = currentSession.messages[currentSession.messages.length - 1];
        if (lastMessage && lastMessage.role === 'assistant') {
          updateAssistantMessage(
            currentSessionId,
            lastMessage.id,
            "[Cancelled by user]",
            (lastMessage.thinking || '') + "\nRequest Cancelled by User.\n",
            false
          );
        }
      }
    }
  };

  const handleImageUpload = (file: File) => {
    const reader = new FileReader();
    reader.onload = (e) => {
      const result = e.target?.result as string;
      const newFile: UploadedFile = {
        id: `img-${Date.now()}`,
        name: file.name,
        type: file.type,
        size: file.size,
        url: result
      };
      setUploadedFiles(prev => [...prev, newFile]);
      setUploadedImage(result); // Keep for backward compatibility
      console.log('Image uploaded:', file.name, file.type, 'Size:', file.size);
    };
    reader.readAsDataURL(file);
  };

  const handleFileUpload = async (file: File) => {
    try {
      // å¯¼å…¥å¢å¼ºçš„æ–‡ä»¶å¤„ç†å·¥å…·
      const { 
        processDocument, 
        analyzeFileSupport, 
        generateUploadRecommendation,
        isFileSizeAcceptable,
        isFileFormatSupported
      } = await import('../utils/fileProcessing');
      
      // è·å–å½“å‰æ¨¡å‹ä¿¡æ¯
      const modelInfo = MODEL_MAPPING[model];
      const provider = String(modelInfo?.provider || 'unknown').toLowerCase();
      
      console.log('ğŸ” handleFileUpload Debug:', {
        model,
        modelInfo,
        originalProvider: modelInfo?.provider,
        convertedProvider: provider,
        fileInfo: {
          name: file.name,
          size: file.size,
          type: file.type,
          sizeMB: (file.size / 1024 / 1024).toFixed(2)
        }
      });
      
      // 0. é¦–å…ˆæ£€æŸ¥å½“å‰æ¨¡å‹æ˜¯å¦æ”¯æŒæ–‡æ¡£å¤„ç†
      if (!modelInfo?.supports?.documents) {
        const shouldSwitch = confirm(
          `å½“å‰æ¨¡å‹ ${model} ä¸æ”¯æŒæ–‡æ¡£å¤„ç†åŠŸèƒ½ã€‚\n\n` +
          `æ¨èåˆ‡æ¢åˆ°æ”¯æŒæ–‡æ¡£çš„æ¨¡å‹ï¼š\n` +
          `â€¢ GPT-4.1 (OpenAIæ——èˆ°æ¨¡å‹)\n` +
          `â€¢ GPT-4o æˆ– GPT-4o-mini (å¤šæ¨¡æ€æ¨¡å‹)\n` +
          `â€¢ Gemini 2.5 Pro/Flash (Googleæ¨¡å‹)\n\n` +
          `æ˜¯å¦è¦ç»§ç»­è¿›è¡Œæœ¬åœ°æ–‡æœ¬æå–ï¼Ÿ`
        );
        
        if (!shouldSwitch) {
          return;
        }
        
        // ç”¨æˆ·é€‰æ‹©ç»§ç»­ï¼Œä½†åªèƒ½è¿›è¡Œæœ¬åœ°å¤„ç†
        console.log('âš ï¸ ç”¨æˆ·é€‰æ‹©åœ¨ä¸æ”¯æŒæ–‡æ¡£çš„æ¨¡å‹ä¸Šè¿›è¡Œæœ¬åœ°å¤„ç†');
      }
      
      // 1. é¦–å…ˆæ£€æŸ¥æ–‡ä»¶æ ¼å¼æ”¯æŒ
      const formatCheck = isFileFormatSupported(file, provider);
      if (!formatCheck.supported) {
        const shouldContinue = confirm(`${formatCheck.reason}\n\n${formatCheck.recommendation}\n\næ˜¯å¦ä»è¦å°è¯•æœ¬åœ°æ–‡æœ¬æå–ï¼Ÿ`);
        if (!shouldContinue) {
          return;
        }
      }
      
      // 2. ç„¶åæ£€æŸ¥æ–‡ä»¶å¤§å°
      const fileSizeMB = file.size / 1024 / 1024;
      const maxSize = 32; // OpenAIçš„æœ€å¤§é™åˆ¶
      
      console.log('ğŸ” æ–‡ä»¶å¤§å°æ£€æŸ¥:', {
        fileSizeMB: fileSizeMB.toFixed(2),
        maxSize,
        provider,
        fileType: file.type
      });
      
      const sizeAcceptable = isFileSizeAcceptable(file, provider, maxSize);
      console.log('ğŸ” æ–‡ä»¶å¤§å°æ£€æŸ¥ç»“æœ:', sizeAcceptable);
      
      if (!sizeAcceptable) {
        // æ ¹æ®æä¾›å•†ç»™å‡ºå…·ä½“çš„å¤§å°é™åˆ¶æç¤º
        let errorMessage = `æ–‡ä»¶å¤ªå¤§ï¼æ–‡ä»¶å¤§å°ï¼š${fileSizeMB.toFixed(1)}MB\n\n`;
        
        if (provider === 'openai' || provider === 'gpt') {
          errorMessage += `OpenAIæ”¯æŒçš„æ–‡æ¡£æœ€å¤§32MB`;
        } else if (provider === 'gemini' || provider === 'google') {
          errorMessage += `Geminiå†…è”æ–‡æ¡£æœ€å¤§20MBï¼Œå¤§æ–‡ä»¶å¯ä½¿ç”¨File API`;
        } else {
          errorMessage += `å½“å‰æ¨¡å‹æœ€å¤§æ”¯æŒ${maxSize}MBçš„æ–‡ä»¶`;
        }
        
        alert(errorMessage);
        return;
      }
      
      // 3. åˆ†ææ–‡ä»¶æ”¯æŒæƒ…å†µ
      const supportAnalysis = analyzeFileSupport(file, provider);
      console.log('File support analysis:', supportAnalysis);
      
      // ç”Ÿæˆä¸Šä¼ å»ºè®®å¹¶æ˜¾ç¤ºç»™ç”¨æˆ·
      const recommendation = generateUploadRecommendation(file, provider);
      console.log('Upload recommendation:', recommendation);
      
      // æ ¹æ®åˆ†æç»“æœé€‰æ‹©å¤„ç†æ–¹å¼
      if (supportAnalysis.supported && supportAnalysis.method === 'native' && modelInfo?.supports?.documents) {
        // åŸç”Ÿæ–‡æ¡£å¤„ç†
        try {
          const apiKey = getApiKeyForProvider(modelInfo.provider);
          if (!apiKey) {
            alert(`è¯·å…ˆè®¾ç½®${modelInfo.provider}çš„APIå¯†é’¥æ‰èƒ½ä½¿ç”¨æ–‡æ¡£å¤„ç†åŠŸèƒ½`);
            return;
          }
          
          // æ˜¾ç¤ºä¸Šä¼ è¿›åº¦æç¤º
          const uploadingFile: UploadedFile = {
            id: `uploading-${Date.now()}`,
            name: file.name,
            type: file.type,
            size: file.size,
            content: `ğŸ”„ æ­£åœ¨ä¸Šä¼ åˆ°${provider}...`,
            provider: provider
          };
          setUploadedFiles(prev => [...prev, uploadingFile]);
          
          // åˆ›å»ºFormDataä¸Šä¼ æ–‡ä»¶
          const formData = new FormData();
          formData.append('file', file);
          formData.append('model', model);
          formData.append('apiKey', apiKey);
          
          const uploadResponse = await fetch('/api/files/upload', {
            method: 'POST',
            body: formData,
          });
          
          if (!uploadResponse.ok) {
            const errorData = await uploadResponse.json();
            throw new Error(errorData.error || 'æ–‡ä»¶ä¸Šä¼ å¤±è´¥');
          }
          
          const uploadResult = await uploadResponse.json();
          
          // æ›´æ–°æ–‡ä»¶çŠ¶æ€ä¸ºæˆåŠŸ
          const successFile: UploadedFile = {
            id: `file-${Date.now()}`,
            name: file.name,
            type: file.type,
            size: file.size,
            content: `âœ… [${provider}åŸç”Ÿæ–‡æ¡£] ${file.name}\n\næ–‡ä»¶å·²æˆåŠŸä¸Šä¼ åˆ°${provider}çš„æ–‡æ¡£å¤„ç†æœåŠ¡`,
            // å­˜å‚¨æ–‡ä»¶å¼•ç”¨ä¿¡æ¯
            fileId: uploadResult.fileId,
            fileUri: uploadResult.fileUri,
            provider: uploadResult.provider
          };
          
          // ç§»é™¤ä¸Šä¼ ä¸­çš„æ–‡ä»¶ï¼Œæ·»åŠ æˆåŠŸçš„æ–‡ä»¶
          setUploadedFiles(prev => 
            prev.filter(f => f.id !== uploadingFile.id).concat(successFile)
          );
          
          console.log('âœ… File uploaded to API:', file.name, 'Provider:', provider);
          
        } catch (error: any) {
          console.error('âŒ Error uploading file to API:', error);
          
          // ç§»é™¤ä¸Šä¼ ä¸­çš„æ–‡ä»¶
          setUploadedFiles(prev => prev.filter(f => f.id.startsWith('uploading-')));
          
          // è¯¢é—®ç”¨æˆ·æ˜¯å¦å›é€€åˆ°æœ¬åœ°å¤„ç†
          const shouldFallback = confirm(`æ–‡æ¡£ä¸Šä¼ å¤±è´¥: ${error.message}\n\næ˜¯å¦å°è¯•æœ¬åœ°æ–‡æœ¬æå–ï¼Ÿ`);
          
          if (shouldFallback) {
            // å›é€€åˆ°æœ¬åœ°å¤„ç†
            const processingResult = await processDocument(file, provider);
            
            let content = processingResult.file.content || '';
            if (processingResult.warnings && processingResult.warnings.length > 0) {
              content += `\n\nâš ï¸ å¤„ç†è­¦å‘Š:\n${processingResult.warnings.join('\n')}`;
            }
            if (processingResult.errors && processingResult.errors.length > 0) {
              content += `\n\nâŒ å¤„ç†é”™è¯¯:\n${processingResult.errors.join('\n')}`;
            }
            
            const newFile: UploadedFile = {
              id: `file-${Date.now()}`,
              name: processingResult.file.name,
              type: processingResult.file.type,
              size: processingResult.file.size,
              content: `âš ï¸ [æœ¬åœ°å¤„ç†] ${content}`
            };
            setUploadedFiles(prev => [...prev, newFile]);
            console.log('ğŸ“„ File processed locally:', file.name, file.type, 'Size:', file.size);
            
            // æ ¹æ®å¤„ç†çŠ¶æ€ç»™å‡ºåé¦ˆ
            if (processingResult.status === 'success') {
              console.log('âœ… æ–‡ä»¶å¤„ç†æˆåŠŸ');
            } else if (processingResult.status === 'partial') {
              setTimeout(() => {
                alert(`âš ï¸ æ–‡ä»¶éƒ¨åˆ†å¤„ç†æˆåŠŸã€‚\n\n${processingResult.warnings?.join('\n') || ''}`);
              }, 100);
            } else if (processingResult.status === 'failed') {
              setTimeout(() => {
                alert(`âŒ æ–‡ä»¶å¤„ç†å¤±è´¥ã€‚\n\n${processingResult.errors?.join('\n') || ''}`);
              }, 100);
            }
            
            // å¦‚æœæ˜¯å› ä¸ºæä¾›å•†ä¸æ”¯æŒï¼Œç»™å‡ºå»ºè®®
            if (!supportAnalysis.supported) {
              setTimeout(() => {
                alert(`${recommendation}\n\næ–‡ä»¶å·²è¿›è¡Œæœ¬åœ°æ–‡æœ¬æå–ï¼Œä½†å¯èƒ½æ— æ³•è·å¾—æœ€ä½³æ•ˆæœã€‚`);
              }, 100);
            }
          }
        }
      } else {
        // æœ¬åœ°å¤„ç†ï¼ˆæ–‡æœ¬æå–æˆ–ä¸æ”¯æŒçš„æä¾›å•†ï¼‰
        const processingResult = await processDocument(file, provider);
        
        let content = processingResult.file.content || '';
        if (processingResult.warnings && processingResult.warnings.length > 0) {
          content += `\n\nâš ï¸ å¤„ç†è­¦å‘Š:\n${processingResult.warnings.join('\n')}`;
        }
        if (processingResult.errors && processingResult.errors.length > 0) {
          content += `\n\nâŒ å¤„ç†é”™è¯¯:\n${processingResult.errors.join('\n')}`;
        }
        
        const newFile: UploadedFile = {
          id: `file-${Date.now()}`,
          name: processingResult.file.name,
          type: processingResult.file.type,
          size: processingResult.file.size,
          content: `âš ï¸ [æœ¬åœ°å¤„ç†] ${content}`
        };
        setUploadedFiles(prev => [...prev, newFile]);
        console.log('ğŸ“„ File processed locally:', file.name, file.type, 'Size:', file.size);
        
        // æ ¹æ®å¤„ç†çŠ¶æ€ç»™å‡ºåé¦ˆ
        if (processingResult.status === 'success') {
          console.log('âœ… æ–‡ä»¶å¤„ç†æˆåŠŸ');
        } else if (processingResult.status === 'partial') {
          setTimeout(() => {
            alert(`âš ï¸ æ–‡ä»¶éƒ¨åˆ†å¤„ç†æˆåŠŸã€‚\n\n${processingResult.warnings?.join('\n') || ''}`);
          }, 100);
        } else if (processingResult.status === 'failed') {
          setTimeout(() => {
            alert(`âŒ æ–‡ä»¶å¤„ç†å¤±è´¥ã€‚\n\n${processingResult.errors?.join('\n') || ''}`);
          }, 100);
        }
        
        // å¦‚æœæ˜¯å› ä¸ºæä¾›å•†ä¸æ”¯æŒï¼Œç»™å‡ºå»ºè®®
        if (!supportAnalysis.supported) {
          setTimeout(() => {
            alert(`${recommendation}\n\næ–‡ä»¶å·²è¿›è¡Œæœ¬åœ°æ–‡æœ¬æå–ï¼Œä½†å¯èƒ½æ— æ³•è·å¾—æœ€ä½³æ•ˆæœã€‚`);
          }, 100);
        }
      }
    } catch (error) {
      console.error('ğŸ’¥ Error processing file:', error);
      alert('æ–‡ä»¶å¤„ç†å¤±è´¥ï¼Œè¯·é‡è¯•ã€‚å¦‚æœé—®é¢˜æŒç»­å­˜åœ¨ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼å’Œå¤§å°ã€‚');
    }
  };

  const handleRemoveFile = (fileId: string) => {
    setUploadedFiles(prev => {
      const newFiles = prev.filter(f => f.id !== fileId);
      // If removing an image, also clear uploadedImage if it matches
      const removedFile = prev.find(f => f.id === fileId);
      if (removedFile && removedFile.type.startsWith('image/') && removedFile.url === uploadedImage) {
        setUploadedImage(null);
      }
      return newFiles;
    });
  };

  // Add regenerate message functionality
  const regenerateMessage = async (messageId: string, newModel?: string) => {
    if (!currentSessionId || !currentSession) {
      console.error("No current session to regenerate message in.");
      return;
    }

    setIsLoading(true);

    // Find the message to regenerate and its index
    const messageIndex = currentSession.messages.findIndex(m => m.id === messageId);
    if (messageIndex === -1) {
      console.error("Message not found for regeneration");
      setIsLoading(false);
      return;
    }

    // Get all messages up to and including the user message that prompted this response
    let contextMessages = [];
    let userMessageFound = false;
    
    // Work backwards to find the user message that prompted this response
    for (let i = messageIndex - 1; i >= 0; i--) {
      if (currentSession.messages[i].role === 'user') {
        userMessageFound = true;
        contextMessages.unshift(currentSession.messages[i]); // Add the user message
        break;
      }
    }

    if (!userMessageFound) {
      console.error("Could not find preceding user message for regeneration");
      setIsLoading(false);
      return;
    }

    // Add all earlier conversation history for context
    const historyMessages = currentSession.messages.slice(0, messageIndex - 1);
    contextMessages = [...historyMessages, ...contextMessages];

    // Mark the current message as thinking
    setSessions(prevSessions =>
      prevSessions.map(s =>
        s.id === currentSessionId
          ? {
              ...s,
              messages: s.messages.map((m, i) =>
                i === messageIndex
                  ? { ...m, content: '', thinking: '', isThinking: true }
                  : m
              )
            }
          : s
      )
    );

    // Get the latest user message for regeneration
    const userMessage = contextMessages[contextMessages.length - 1];

    // Determine which model to use
    const modelToUse = newModel || currentSession.model || model;

    // Set up the request
    abortControllerRef.current = new AbortController();
    let accumulatedResponse = '';
    let reasoningBuffer = '';

    try {
      const response = await fetch('/api/chat', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        signal: abortControllerRef.current.signal,
        body: JSON.stringify(
          addApiKeyToRequest({
            model: modelToUse,
            messages: contextMessages.map(m => ({ role: m.role, content: m.content })),
            stream: true,
            ...advancedSettings,
          } as LLMRequest)
        ),
      });

      if (!response.ok || !response.body) {
        throw new Error(`API Error: ${response.status} ${response.statusText}`);
      }

      // æ·»åŠ æµè§ˆå™¨å…¼å®¹æ€§æ£€æŸ¥
      if (!response.body.getReader) {
        throw new Error('ReadableStream not supported in this environment');
      }

      const reader = response.body.getReader();
      const decoder = new TextDecoder();
      let sseBuffer = ''; // Buffer for SSE messages
      
      while (true) {
        const { value, done } = await reader.read();
        if (done) {
          // Final update when stream is done
          updateAssistantMessage(
            currentSessionId,
            messageId,
            accumulatedResponse,
            reasoningBuffer,
            false
          );
          
          setIsLoading(false);
          break;
        }

        const chunkText = decoder.decode(value, { stream: true });
        sseBuffer += chunkText; // Append to buffer
        
        // Process complete SSE events
        let delimiterIndex;
        while ((delimiterIndex = sseBuffer.indexOf('\n\n')) !== -1) {
          const eventText = sseBuffer.slice(0, delimiterIndex);
          sseBuffer = sseBuffer.slice(delimiterIndex + 2); // Keep the rest
          
          if (!eventText.startsWith('data: ')) continue;
          const jsonData = eventText.substring(6).trim();
          
          if (jsonData === '[DONE]' || jsonData.includes('"type":"done_event"')) {
            updateAssistantMessage(
              currentSessionId,
              messageId,
              accumulatedResponse,
              reasoningBuffer,
              false
            );
            
            setIsLoading(false);
            return;
          }
          
          try {
            const parsedSSE = JSON.parse(jsonData);
            
            // Handle direct thinking data from Gemini (new format)
            if (parsedSSE.thinking) {
              // Geminiæ€è€ƒå†…å®¹ç›´æ¥å¤„ç†
              reasoningBuffer += `${parsedSSE.thinking}\n`;
              updateAssistantMessage(currentSessionId, messageId, accumulatedResponse, reasoningBuffer, true);
            } else if (parsedSSE.content) {
              // Regular content to display in the message
              accumulatedResponse += parsedSSE.content;
              
              // Update the message with new content, preserve thinking state
              updateAssistantMessage(currentSessionId, messageId, accumulatedResponse, reasoningBuffer, true);
            } else if (parsedSSE.reasoning_content) {
              // Add reasoning content to the reasoning buffer
              reasoningBuffer += parsedSSE.reasoning_content + "\n";
              
              // Update the message with new thinking content but keep isThinking true
              updateAssistantMessage(currentSessionId, messageId, accumulatedResponse, reasoningBuffer, true);
            } else if (parsedSSE.error) {
              console.error("SSE Error Chunk:", parsedSSE.error, parsedSSE.details);
              accumulatedResponse += `\n\n[Error: ${parsedSSE.error}]`;
              
              updateAssistantMessage(
                currentSessionId,
                messageId,
                accumulatedResponse,
                reasoningBuffer + `Error: ${parsedSSE.error}\n`,
                false
              );
              
              setIsLoading(false);
              return;
            } else if (parsedSSE.finish_reason) {
              // When we get a finish reason, mark thinking as complete
              updateAssistantMessage(currentSessionId, messageId, accumulatedResponse, reasoningBuffer, false);
              setIsLoading(false);
            } else {
              // Legacy format handling with {type, data}
              const { type: stepType, data: eventData } = parsedSSE;
              
              if (eventData && eventData.error) {
                console.error("SSE Error Chunk:", eventData.error, eventData.details);
                accumulatedResponse += `\n\n[Error: ${eventData.error}]`;
                
                updateAssistantMessage(
                  currentSessionId,
                  messageId,
                  accumulatedResponse,
                  reasoningBuffer + `Error: ${eventData.error}\n`,
                  false
                );
                
                setIsLoading(false);
                return;
              }

              // Process different types of chunks
              if (stepType === 'thinking_step' && eventData.thinking) {
                // Geminiçš„æ€è€ƒå†…å®¹ï¼ˆä½¿ç”¨thinkingå­—æ®µï¼‰
                reasoningBuffer += `${eventData.thinking}\n`;
                
                // Update the message with new thinking content but keep isThinking true
                updateAssistantMessage(currentSessionId, messageId, accumulatedResponse, reasoningBuffer, true);
              } else if (stepType === 'thinking_step' && eventData.content) {
                // Add to reasoning buffer when we get thinking steps
                reasoningBuffer += `${eventData.content}\n`;
                
                // Update the message with new thinking content but keep isThinking true
                updateAssistantMessage(currentSessionId, messageId, accumulatedResponse, reasoningBuffer, true);
              } else if (stepType === 'thinking_step' && eventData.reasoning_content) {
                // Add to reasoning buffer when we get reasoning content
                reasoningBuffer += `${eventData.reasoning_content}\n`;
                
                // Update the message with new thinking content but keep isThinking true
                updateAssistantMessage(currentSessionId, messageId, accumulatedResponse, reasoningBuffer, true);
              } else if (stepType === 'step' && eventData.content) {
                reasoningBuffer += `Step: ${eventData.content}\n`;
                updateAssistantMessage(currentSessionId, messageId, accumulatedResponse, reasoningBuffer, true);
              } else if (stepType === 'tool_use_step' && eventData) {
                let toolInfo = 'Tool Invocation:\n';
                if(eventData.tool_name) toolInfo += `  Name: ${eventData.tool_name}\n`;
                if(eventData.tool_id) toolInfo += `  ID: ${eventData.tool_id}\n`;
                if(eventData.tool_input) toolInfo += `  Input: ${JSON.stringify(eventData.tool_input, null, 2)}\n`;
                if(eventData.tool_arguments) toolInfo += `  Arguments: ${JSON.stringify(eventData.tool_arguments, null, 2)}\n`;
                if(eventData.tool_arguments_raw) toolInfo += `  Arguments (raw): ${eventData.tool_arguments_raw}\n`;
                
                reasoningBuffer += toolInfo;
                updateAssistantMessage(currentSessionId, messageId, accumulatedResponse, reasoningBuffer, true);
              } else if (stepType === 'content_chunk' && eventData.content) {
                accumulatedResponse += eventData.content;
                updateAssistantMessage(currentSessionId, messageId, accumulatedResponse, reasoningBuffer, true);
              }
            }
          } catch (e) {
            console.error('Error parsing SSE JSON data:', jsonData, e);
          }
        }
      }
    } catch (error: any) {
      if (error.name === 'AbortError') {
        console.log('Request aborted by user.');
        updateAssistantMessage(
          currentSessionId,
          messageId,
          "[Cancelled by user]",
          reasoningBuffer + "\nRequest Cancelled by User.\n",
          false
        );
      } else {
        console.error('Error regenerating message:', error);
        const errorMessage = `Error: ${error.message || 'Failed to get response.'}`;
        updateAssistantMessage(
          currentSessionId,
          messageId,
          errorMessage,
          reasoningBuffer + errorMessage + `\n`,
          false
        );
      }
      setIsLoading(false);
    }

    // Update the session model if we switched models for this message
    if (newModel && newModel !== currentSession.model) {
      setSessions(prevSessions =>
        prevSessions.map(s =>
          s.id === currentSessionId
            ? { ...s, model: newModel }
            : s
        )
      );
      setModel(newModel);
    }
  };

  if (!currentSession) {
    return <div className="flex items-center justify-center min-h-screen text-white">Loading session...</div>; 
  }

  return (
    <div className="flex min-h-screen bg-gradient-to-br from-slate-950 via-slate-900 to-slate-950">
      {/* Sidebar */}
      <Sidebar 
        sessions={sessions} 
        currentSessionId={currentSessionId} 
        onNewSession={handleNewSession} 
        onSwitchSession={handleSwitchSession}
        onArchiveSession={handleArchiveSession}
        onDeleteSession={handleDeleteSession}
        onBatchDeleteSessions={handleBatchDeleteSessions}
        isOpen={isSidebarOpen}
      />
      
      {/* å°å±å¹•èƒŒæ™¯é®ç½© */}
      {isSidebarOpen && (
        <div 
          className="fixed inset-0 bg-black/50 backdrop-blur-sm z-40 lg:hidden"
          onClick={() => setIsSidebarOpen(false)}
        />
      )}
      
      {/* Main Content Area - å“åº”å¼ä¾§è¾¹æ é€‚é… */}
      <div className={`flex flex-col flex-1 min-w-0 transition-all duration-300 ${
        isSidebarOpen ? 'lg:ml-80' : 'ml-0'
      }`}>
        {/* Top Bar */}
        <TopBar 
          currentSessionName={currentSession?.name}
          onNewSession={handleNewSession}
          onArchiveSession={currentSession && !currentSession.archived ? () => handleArchiveSession(currentSession.id) : undefined}
          onDeleteSession={currentSession ? () => handleDeleteSession(currentSession.id) : undefined}
          onToggleSidebar={() => setIsSidebarOpen(!isSidebarOpen)}
          isSidebarOpen={isSidebarOpen}
        />
        
        {/* Content Container - ä¼˜åŒ–æ¨ªå‘å¸ƒå±€å’Œè‡ªé€‚åº”è®¾è®¡ */}
        <div className="flex flex-col flex-1 items-center w-full px-3 sm:px-4 lg:px-6 xl:px-8 py-4 sm:py-6">
          <div className="w-full max-w-3xl sm:max-w-4xl lg:max-w-5xl xl:max-w-6xl 2xl:max-w-7xl">
            {/* Model Selector and Settings */}
            <div className="bg-slate-900/50 backdrop-blur-sm rounded-xl sm:rounded-2xl border border-slate-700/50 p-4 sm:p-6 mb-4 sm:mb-6 shadow-xl">
              <div className="flex flex-col gap-3 sm:gap-4">
                <ModelSelector 
                  value={model}
                  onChange={(newModel) => { 
                    setModel(newModel); 
                    if(currentSessionId) {
                      setSessions(prev => prev.map(s => s.id === currentSessionId ? {...s, model: newModel} : s));
                    }
                  }}
                  disabledProviders={disabledProviders}
                />
                
                {/* Advanced Settings */}
                <AdvancedSettings
                  selectedModel={model}
                  settings={advancedSettings}
                  onChange={setAdvancedSettings}
                  onReset={() => setAdvancedSettings({})}
                />
              </div>
            </div>

            {/* Message List Area - è‡ªé€‚åº”é«˜åº¦å’Œå®½åº¦ */}
            <div className={`flex flex-col flex-1 bg-slate-900/30 backdrop-blur-sm rounded-xl sm:rounded-2xl border border-slate-700/50 shadow-2xl overflow-hidden mb-4 sm:mb-6 ${
              currentSession?.messages.length === 0 
                ? 'min-h-[50vh] sm:min-h-[55vh] lg:min-h-[60vh]' 
                : 'min-h-[45vh] sm:min-h-[50vh] lg:min-h-[55vh] max-h-[60vh] sm:max-h-[65vh] lg:max-h-[70vh]'
            }`}>
              {currentSession?.messages.length === 0 && !isLoading && (
                <div className="flex flex-col items-center justify-center h-full text-slate-400 p-4 sm:p-8">
                  <div className="w-16 h-16 sm:w-20 sm:h-20 lg:w-24 lg:h-24 mb-4 sm:mb-6 rounded-full bg-gradient-to-br from-blue-600/20 to-purple-600/20 flex items-center justify-center">
                    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" strokeWidth={1.5} stroke="currentColor" className="w-8 h-8 sm:w-10 sm:h-10 lg:w-12 lg:h-12">
                      <path strokeLinecap="round" strokeLinejoin="round" d="M8.625 12a.375.375 0 11-.75 0 .375.375 0 01.75 0zm0 0H8.25m4.125 0a.375.375 0 11-.75 0 .375.375 0 01.75 0zm0 0H12m4.125 0a.375.375 0 11-.75 0 .375.375 0 01.75 0zm0 0h-.375M21 12c0 4.556-3.86 8.25-8.625 8.25S3.75 16.556 3.75 12s3.86-8.25 8.625-8.25S21 7.444 21 12z" />
                    </svg>
                  </div>
                  <h2 className="text-xl sm:text-2xl lg:text-3xl font-semibold text-slate-200 mb-2 text-center">How can I help you today?</h2>
                  <p className="text-sm sm:text-base text-slate-400 text-center">Start a conversation with your AI assistant</p>
                </div>
              )}
              {currentSession && (
                <MessageList 
                  messages={currentSession.messages} 
                  onRegenerate={regenerateMessage}
                  currentModel={model}
                />
              )}
            </div>

            {/* Chat Input Area */}
            <ChatInput 
              value={input} 
              onChange={setInput} 
              onSend={handleSend} 
              onImageUpload={handleImageUpload}
              onFileUpload={handleFileUpload}
              disabled={isLoading} 
              onCancel={handleCancel} 
              showCancel={isLoading}
              currentModel={model}
              uploadedFiles={uploadedFiles}
              onRemoveFile={handleRemoveFile}
            />
          </div>
        </div>
      </div>
    </div>
  );
}

